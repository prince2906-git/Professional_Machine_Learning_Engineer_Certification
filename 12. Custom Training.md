We can explored the options that Google Cloud provides to build machine learning models by using pre-trained APIs,
where we directly call Google’s trained models to solve your problems, BigQuery ML, where we write a few lines of SQL
code to train our own model, and AutoML,
where we build your ML model with your own data through a UI.

But if we want to create ur own machine learning environment to experiment with and build your own pipeline, we need
custom training.
Before any coding begins, we must determine what environment required for ML training code to use.
There are two options: a pre-built container or a custom container.

A pre-built container is like a furnished kitchen with cabinets, appliances, and cookware.
So, if your ML training needs a platform like Python, TensorFlow, and PyTorch, and you’re not particular about the
underlying infrastructure to run on, or to use our kitchen analogy, which oven or knife you use, a pre-built container
is probably your best choice.

    A custom container is like an empty kitchen with no cabinets, appliances, or cookware.You define the exact appliances and tools that you prefer to cook with.
    That means you must determine the details like the environment, machine type, and disks when creating the custom container.
    In terms of the tools to code your ML model, you can use Vertex AI Workbench.

### Vertex AI Workbench

       Vertex AI Workbench as a Jupyter notebook deployed in a single development environment that supports the entire data science workflow, from exploring to training and then deploying a machine learning model.
       Vertex AI Workbench is a managed service that provides a Jupyter notebook environment for data scientists and machine learning engineers to build, train, and deploy machine learning models.

### ML Library

    An ML library is a collection of pre-written code that can be used to perform machine learning tasks.
    These libraries can save developers time and effort by providing them with the tools they need to build machine learning models without having to write everything from the beginning.
     Popular ML libraries like TensorFlow, scikit-learn, and PyTorch.

### Tensorflow

    TensorFlow is an open-source machine learning library developed by Google that provides a flexible and efficient platform for building and deploying machine learning models.
    It is widely used in both research and production environments and has a large community of developers and users.
    TensorFlow supports a wide range of machine learning tasks, including deep learning, reinforcement learning, and natural language processing.
    It also provides tools for distributed training, model optimization, and deployment to various platforms, including mobile devices and the web.
    Tensorflow contains multiple abstraction layers.
    The TensorFlow APIs are arranged hierarchically, with the high-level APIs built on the low-level APIs.
    The lowest layer is hardware.
    TensorFlow can run on different hardware platforms including CPU, GPU, and TPU.
    The next layer is the low-level TensorFlow APIs, where you can write your own operations in C++ and call the core, basic, and numeric processing functions written in Python.
    The third layer is the TensorFlow model libraries, which provide the building blocks such as neural network layers and evaluation metrics to create a custom ML model.
    The high-level TensorFlow APIs like Keras sit on top of this hierarchy.
    They hide the ML building details and automatically deploy the training.
    They can be your most used APIs.
    Note that Vertex AI fully hosts TensorFlow from low-level to high-level APIs.
    Regardless of which abstraction level you are writing your TensorFlow code at, Vertex AI gives you a managed service.
    Now let’s look at an example of using tf.keras, a high-level TensorFlow library commonly used, to build a simple regression model.

    
    Typically, it takes three fundamental steps: In step one, you create a model, where you piece together the layers of a neural network.
    In step two you compile the model, where you specify hyperparameters such as performance evaluation and model optimization.
    Finally, you train your model to find the best fit.
    The first step is to create a model by using tf.keras.Sequential.

    Apart from Tensorflow, Google is consistently introducing new frameworks.
    One of the most promising frameworks is JAX.
    JAX is a high-performance numerical computation library that is highly flexible and easy to use.
    It offers new possibilities for both research and production environments.
    


     
